fit:
  model:
    model:
      class_path: crop_health_model.models.model.ResNet
      init_args:
        weights: "DEFAULT"
        num_classes: 17 # 2 for binary, 13 for single-HLT, 17 for multi-HLT
        num_layers: 18
  data:
    batch_size: 32
    data_dir: .data
    annotations_file: annotations.csv
    task: "multi-HLT" # binary, single-HLT, or multi-HLT
    data_split: [0.8, 0.2]
    num_workers: 16
    limit: null
    train_transforms:
    - class_path: torchvision.transforms.Resize
      init_args:
        interpolation: 2 # corresponds to BILINEAR
        size: 256
    - class_path: torchvision.transforms.CenterCrop
      init_args: 
        size: 224
    test_transforms:
    - class_path: torchvision.transforms.Resize
      init_args:
        interpolation: 2
        size: 256
    - class_path: torchvision.transforms.CenterCrop
      init_args: 
        size: 224
    normalization:
      class_path: torchvision.transforms.Normalize
      init_args:
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]
  trainer:
    deterministic: true
    max_epochs: 25
    devices: 
    - 0
    - 1
    callbacks:
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: "val_loss"
        mode: "min"
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        monitor: "val_loss"
        mode: "min"
        save_top_k: 1
        filename: "crop_health_model-{epoch}-{step}-{val_loss:.3f}"
  optimizer:
    class_path: torch.optim.Adam
    init_args:
      lr: 0.001
